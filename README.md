# ML-AI
---
The llm utilizes the python librarys:

  dataset to load the convo_ai form HuggingFace's datasets
  
  transformers: to utilize the gpt2 model to train with pre loaded weights

## Issues

The data being fed in could have been cleaned up better and filtered out more. The dataset itself was not the best and there are future iterations on HuggingFaces library, however the amount of iterations are too many to train for my current computer

The amount of iterations total was 2778 and the training took about 2 hours on a M1 Macbook Pro with 16gb of ram

Tried to run this on google colab but ran into issues getting dependencies to install properly 

## What was learned
Learned where to find raw data to be able to process

Learned how to process and train said data

Learned how to interact with the trained data to be able to create a chat bot

## Improvements to be made/takeaways

Learn about attention masks and pad_tokens to be able to enhance the training

If possible try training a largest set of data by utilizing google colab


## Image of input and output
![image](https://github.com/manan883/ML-AI/assets/55415553/586d9d04-0d05-413b-8ab7-7344167fce2a)
